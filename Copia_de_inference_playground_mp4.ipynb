{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Copia de inference_playground_mp4.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/julioteleco/SAM/blob/master/Copia_de_inference_playground_mp4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aWBuYb2UDIO"
      },
      "source": [
        "# SAM: Animation Inference Playground"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bXkvGVI3Wa2d"
      },
      "source": [
        "# Nueva sección"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uuviq3qQkUFy"
      },
      "source": [
        "import os\n",
        "os.chdir('/content')\n",
        "CODE_DIR = 'SAM'"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQ6XEmlHlXbk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1022568e-14da-4ffe-a861-36c9c34fdd33"
      },
      "source": [
        "!git clone https://github.com/yuval-alaluf/SAM.git $CODE_DIR"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'SAM'...\n",
            "remote: Enumerating objects: 104, done.\u001b[K\n",
            "remote: Counting objects: 100% (104/104), done.\u001b[K\n",
            "remote: Compressing objects: 100% (87/87), done.\u001b[K\n",
            "remote: Total 104 (delta 22), reused 92 (delta 14), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (104/104), 3.45 MiB | 39.22 MiB/s, done.\n",
            "Resolving deltas: 100% (22/22), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JaRUFuVHkzye",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f697655f-2f62-41d1-c967-ecb2ddb4fcc9"
      },
      "source": [
        "!wget https://github.com/ninja-build/ninja/releases/download/v1.8.2/ninja-linux.zip\n",
        "!sudo unzip ninja-linux.zip -d /usr/local/bin/\n",
        "!sudo update-alternatives --install /usr/bin/ninja ninja /usr/local/bin/ninja 1 --force "
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-02-16 05:33:09--  https://github.com/ninja-build/ninja/releases/download/v1.8.2/ninja-linux.zip\n",
            "Resolving github.com (github.com)... 192.30.255.112\n",
            "Connecting to github.com (github.com)|192.30.255.112|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github-releases.githubusercontent.com/1335132/d2f252e2-9801-11e7-9fbf-bc7b4e4b5c83?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20210216%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20210216T053310Z&X-Amz-Expires=300&X-Amz-Signature=96dec3540f121862c6f515bc02acd6bc81a7b58e062958a90f4f9e88f4fbaec0&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=1335132&response-content-disposition=attachment%3B%20filename%3Dninja-linux.zip&response-content-type=application%2Foctet-stream [following]\n",
            "--2021-02-16 05:33:10--  https://github-releases.githubusercontent.com/1335132/d2f252e2-9801-11e7-9fbf-bc7b4e4b5c83?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20210216%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20210216T053310Z&X-Amz-Expires=300&X-Amz-Signature=96dec3540f121862c6f515bc02acd6bc81a7b58e062958a90f4f9e88f4fbaec0&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=1335132&response-content-disposition=attachment%3B%20filename%3Dninja-linux.zip&response-content-type=application%2Foctet-stream\n",
            "Resolving github-releases.githubusercontent.com (github-releases.githubusercontent.com)... 185.199.108.154, 185.199.109.154, 185.199.110.154, ...\n",
            "Connecting to github-releases.githubusercontent.com (github-releases.githubusercontent.com)|185.199.108.154|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 77854 (76K) [application/octet-stream]\n",
            "Saving to: ‘ninja-linux.zip’\n",
            "\n",
            "ninja-linux.zip     100%[===================>]  76.03K  --.-KB/s    in 0.009s  \n",
            "\n",
            "2021-02-16 05:33:10 (8.41 MB/s) - ‘ninja-linux.zip’ saved [77854/77854]\n",
            "\n",
            "Archive:  ninja-linux.zip\n",
            "  inflating: /usr/local/bin/ninja    \n",
            "update-alternatives: using /usr/local/bin/ninja to provide /usr/bin/ninja (ninja) in auto mode\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23baccYQlU9E"
      },
      "source": [
        "os.chdir(f'./{CODE_DIR}')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lEWIzkaLSsFY"
      },
      "source": [
        "from argparse import Namespace\n",
        "import os\n",
        "import sys\n",
        "import pprint\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "sys.path.append(\".\")\n",
        "sys.path.append(\"..\")\n",
        "\n",
        "from datasets.augmentations import AgeTransformer\n",
        "from utils.common import tensor2im\n",
        "from models.psp import pSp"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9J3NEVlESsFl"
      },
      "source": [
        "EXPERIMENT_TYPE = 'ffhq_aging'"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eFjfO9q9SsFm"
      },
      "source": [
        "## Step 1: Download Pretrained Model\n",
        "As part of this repository, we provide our pretrained aging model.\n",
        "We'll download the model for the selected experiments as save it to the folder `../pretrained_models`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e2L9GRCFSsFm"
      },
      "source": [
        "def get_download_model_command(file_id, file_name):\n",
        "    \"\"\" Get wget download command for downloading the desired model and save to directory ../pretrained_models. \"\"\"\n",
        "    current_directory = os.getcwd()\n",
        "    save_path = os.path.join(os.path.dirname(current_directory), \"pretrained_models\")\n",
        "    if not os.path.exists(save_path):\n",
        "        os.makedirs(save_path)\n",
        "    url = r\"\"\"wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id={FILE_ID}' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id={FILE_ID}\" -O {SAVE_PATH}/{FILE_NAME} && rm -rf /tmp/cookies.txt\"\"\".format(FILE_ID=file_id, FILE_NAME=file_name, SAVE_PATH=save_path)\n",
        "    return url    "
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yotXNk8PSsFn"
      },
      "source": [
        "MODEL_PATHS = {\n",
        "    \"ffhq_aging\": {\"id\": \"1XyumF6_fdAxFmxpFcmPf-q84LU_22EMC\", \"name\": \"sam_ffhq_aging.pt\"}\n",
        "}\n",
        "\n",
        "path = MODEL_PATHS[EXPERIMENT_TYPE]\n",
        "download_command = get_download_model_command(file_id=path[\"id\"], file_name=path[\"name\"]) "
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tXUqcxd8SsFo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b2c8109-b66e-4e11-f64e-b161770cbf51"
      },
      "source": [
        "!wget {download_command}"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-02-16 05:34:10--  http://wget/\n",
            "Resolving wget (wget)... failed: Name or service not known.\n",
            "wget: unable to resolve host address ‘wget’\n",
            "--2021-02-16 05:34:10--  https://docs.google.com/uc?export=download&confirm=i59R&id=1XyumF6_fdAxFmxpFcmPf-q84LU_22EMC\n",
            "Resolving docs.google.com (docs.google.com)... 74.125.20.138, 74.125.20.101, 74.125.20.100, ...\n",
            "Connecting to docs.google.com (docs.google.com)|74.125.20.138|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://doc-08-7g-docs.googleusercontent.com/docs/securesc/3288s4o1us02iiims1id6qrftql3lq11/r12uc4jdkq5fsoice2hhek2qiuko5ap2/1613453625000/05457687429326987275/17328170664508509099Z/1XyumF6_fdAxFmxpFcmPf-q84LU_22EMC?e=download [following]\n",
            "--2021-02-16 05:34:10--  https://doc-08-7g-docs.googleusercontent.com/docs/securesc/3288s4o1us02iiims1id6qrftql3lq11/r12uc4jdkq5fsoice2hhek2qiuko5ap2/1613453625000/05457687429326987275/17328170664508509099Z/1XyumF6_fdAxFmxpFcmPf-q84LU_22EMC?e=download\n",
            "Resolving doc-08-7g-docs.googleusercontent.com (doc-08-7g-docs.googleusercontent.com)... 74.125.20.132, 2607:f8b0:400e:c07::84\n",
            "Connecting to doc-08-7g-docs.googleusercontent.com (doc-08-7g-docs.googleusercontent.com)|74.125.20.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://docs.google.com/nonceSigner?nonce=fo2q0ci0tcjhs&continue=https://doc-08-7g-docs.googleusercontent.com/docs/securesc/3288s4o1us02iiims1id6qrftql3lq11/r12uc4jdkq5fsoice2hhek2qiuko5ap2/1613453625000/05457687429326987275/17328170664508509099Z/1XyumF6_fdAxFmxpFcmPf-q84LU_22EMC?e%3Ddownload&hash=6laq9m5irdgrnvl37mlmpjq7l3ibvem2 [following]\n",
            "--2021-02-16 05:34:10--  https://docs.google.com/nonceSigner?nonce=fo2q0ci0tcjhs&continue=https://doc-08-7g-docs.googleusercontent.com/docs/securesc/3288s4o1us02iiims1id6qrftql3lq11/r12uc4jdkq5fsoice2hhek2qiuko5ap2/1613453625000/05457687429326987275/17328170664508509099Z/1XyumF6_fdAxFmxpFcmPf-q84LU_22EMC?e%3Ddownload&hash=6laq9m5irdgrnvl37mlmpjq7l3ibvem2\n",
            "Connecting to docs.google.com (docs.google.com)|74.125.20.138|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://doc-08-7g-docs.googleusercontent.com/docs/securesc/3288s4o1us02iiims1id6qrftql3lq11/r12uc4jdkq5fsoice2hhek2qiuko5ap2/1613453625000/05457687429326987275/17328170664508509099Z/1XyumF6_fdAxFmxpFcmPf-q84LU_22EMC?e=download&nonce=fo2q0ci0tcjhs&user=17328170664508509099Z&hash=ovsniob71v7eck566tdnv991rrg23491 [following]\n",
            "--2021-02-16 05:34:10--  https://doc-08-7g-docs.googleusercontent.com/docs/securesc/3288s4o1us02iiims1id6qrftql3lq11/r12uc4jdkq5fsoice2hhek2qiuko5ap2/1613453625000/05457687429326987275/17328170664508509099Z/1XyumF6_fdAxFmxpFcmPf-q84LU_22EMC?e=download&nonce=fo2q0ci0tcjhs&user=17328170664508509099Z&hash=ovsniob71v7eck566tdnv991rrg23491\n",
            "Connecting to doc-08-7g-docs.googleusercontent.com (doc-08-7g-docs.googleusercontent.com)|74.125.20.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/x-zip]\n",
            "Saving to: ‘/content/pretrained_models/sam_ffhq_aging.pt’\n",
            "\n",
            "/content/pretrained     [            <=>     ]   2.11G  77.6MB/s    in 29s     \n",
            "\n",
            "2021-02-16 05:34:39 (75.2 MB/s) - ‘/content/pretrained_models/sam_ffhq_aging.pt’ saved [2270547237]\n",
            "\n",
            "FINISHED --2021-02-16 05:34:39--\n",
            "Total wall clock time: 30s\n",
            "Downloaded: 1 files, 2.1G in 29s (75.2 MB/s)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mismxuEvSsFp"
      },
      "source": [
        "## Step 3: Define Inference Parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NRzP-untSsFq"
      },
      "source": [
        "Below we have a dictionary defining parameters such as the path to the pretrained model to use and the path to the\n",
        "image to perform inference on.\n",
        "While we provide default values to run this script, feel free to change as needed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pHeJRfsnSsFq"
      },
      "source": [
        "EXPERIMENT_DATA_ARGS = {\n",
        "    \"ffhq_aging\": {\n",
        "        \"model_path\": \"../pretrained_models/sam_ffhq_aging.pt\",\n",
        "        \"transform\": transforms.Compose([\n",
        "            transforms.Resize((256, 256)),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])])\n",
        "    }\n",
        "}"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IgzLA96mSsFq"
      },
      "source": [
        "EXPERIMENT_ARGS = EXPERIMENT_DATA_ARGS[EXPERIMENT_TYPE]"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kqlL9U5uSsFr"
      },
      "source": [
        "## Step 4: Load Pretrained Model\n",
        "We assume that you have downloaded the pretrained aging model and placed it in the path defined above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8khx-2fcSsFr"
      },
      "source": [
        "model_path = EXPERIMENT_ARGS['model_path']\n",
        "ckpt = torch.load(model_path, map_location='cpu')"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fVfLlsfjSsFr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3d16e33-1aed-4bb2-9118-07633bbd5141"
      },
      "source": [
        "opts = ckpt['opts']\n",
        "pprint.pprint(opts)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'aging_lambda': 5.0,\n",
            " 'batch_size': 6,\n",
            " 'board_interval': 50,\n",
            " 'checkpoint_path': None,\n",
            " 'cycle_lambda': 1.0,\n",
            " 'dataset_type': 'ffhq_aging',\n",
            " 'device': 'cuda',\n",
            " 'exp_dir': '',\n",
            " 'id_lambda': 0.1,\n",
            " 'image_interval': 100,\n",
            " 'input_nc': 4,\n",
            " 'l2_lambda': 0.25,\n",
            " 'l2_lambda_aging': 0.25,\n",
            " 'l2_lambda_crop': 1.0,\n",
            " 'label_nc': 0,\n",
            " 'learning_rate': 0.0001,\n",
            " 'lpips_lambda': 0.1,\n",
            " 'lpips_lambda_aging': 0.1,\n",
            " 'lpips_lambda_crop': 0.6,\n",
            " 'max_steps': 500000,\n",
            " 'optim_name': 'ranger',\n",
            " 'output_size': 1024,\n",
            " 'pretrained_psp_path': '',\n",
            " 'save_interval': 2500,\n",
            " 'start_from_encoded_w_plus': True,\n",
            " 'start_from_latent_avg': False,\n",
            " 'stylegan_weights': '',\n",
            " 'target_age': 'uniform_random',\n",
            " 'test_batch_size': 6,\n",
            " 'test_workers': 6,\n",
            " 'train_decoder': False,\n",
            " 'use_weighted_id_loss': True,\n",
            " 'val_interval': 2500,\n",
            " 'w_norm_lambda': 0.005,\n",
            " 'workers': 6}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vxYxSJk1SsFs"
      },
      "source": [
        "# update the training options\n",
        "opts['checkpoint_path'] = model_path"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z4LNoYt_SsFs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5188145b-70a9-4359-d49b-f8a3023fbd00"
      },
      "source": [
        "opts = Namespace(**opts)\n",
        "net = pSp(opts)\n",
        "net.eval()\n",
        "net.cuda()\n",
        "print('Model successfully loaded!')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading SAM from checkpoint: ../pretrained_models/sam_ffhq_aging.pt\n",
            "Model successfully loaded!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3mNH95EJSsFs"
      },
      "source": [
        "### Utils for Generating MP4 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GASwMVmJSsFs"
      },
      "source": [
        "import imageio\n",
        "from tqdm import tqdm\n",
        "import matplotlib\n",
        "\n",
        "matplotlib.use('module://ipykernel.pylab.backend_inline')\n",
        "%matplotlib inline\n",
        "\n",
        "def generate_mp4(out_name, images, kwargs):\n",
        "    writer = imageio.get_writer(out_name + '.mp4', **kwargs)\n",
        "    for image in images:\n",
        "        writer.append_data(image)\n",
        "    writer.close()\n",
        "    \n",
        "\n",
        "def run_on_batch_to_vecs(inputs, net):\n",
        "    _, result_batch = net(inputs.to(\"cuda\").float(), return_latents=True, randomize_noise=False, resize=False)\n",
        "    return result_batch.cpu()\n",
        "\n",
        "\n",
        "def get_result_from_vecs(vectors_a, vectors_b, alpha):\n",
        "    results = []\n",
        "    for i in range(len(vectors_a)):\n",
        "        cur_vec = vectors_b[i] * alpha + vectors_a[i] * (1 - alpha)\n",
        "        res = net(cur_vec.cuda(), randomize_noise=False, input_code=True, input_is_full=True, resize=False)\n",
        "        results.append(res[0])\n",
        "    return results"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y4oqFBfTSsFt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35dae524-3966-440c-c4fa-bd46d9fee915"
      },
      "source": [
        "SEED = 42\n",
        "np.random.seed(SEED)\n",
        "\n",
        "img_transforms = EXPERIMENT_ARGS['transform']\n",
        "n_transition = 25\n",
        "kwargs = {'fps': 40}\n",
        "save_path = \"notebooks/animations\"\n",
        "os.makedirs(save_path, exist_ok=True)\n",
        "\n",
        "#################################################################\n",
        "# TODO: define your image paths here to be fed into the model\n",
        "#################################################################\n",
        "root_dir = 'notebooks/images'\n",
        "ims = ['866', '1287', '2468']\n",
        "im_paths = [os.path.join(root_dir, im) + '.jpg' for im in ims]\n",
        "\n",
        "# NOTE: Please make sure the images are pre-aligned!\n",
        "\n",
        "target_ages = [0, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 90, 80, 70, 60, 50, 40, 30, 20, 10, 0]\n",
        "age_transformers = [AgeTransformer(target_age=age) for age in target_ages]\n",
        "\n",
        "for image_path in im_paths:\n",
        "    image_name = os.path.basename(image_path)\n",
        "    print(f'Working on image: {image_name}')\n",
        "    original_image = Image.open(image_path).convert(\"RGB\")\n",
        "    input_image = img_transforms(original_image)\n",
        "    all_vecs = []\n",
        "    for idx, age_transformer in enumerate(age_transformers):\n",
        "\n",
        "        input_age_batch = [age_transformer(input_image.cpu()).to('cuda')]\n",
        "        input_age_batch = torch.stack(input_age_batch)\n",
        "\n",
        "        # get latent vector for the current target age amount\n",
        "        with torch.no_grad():\n",
        "            result_vec = run_on_batch_to_vecs(input_age_batch, net)\n",
        "            result_image = get_result_from_vecs([result_vec],result_vec,0)[0]\n",
        "            all_vecs.append([result_vec])\n",
        "\n",
        "    images = []\n",
        "    for i in range(1, len(target_ages)):\n",
        "        alpha_vals = np.linspace(0, 1, n_transition).tolist()\n",
        "        for alpha in tqdm(alpha_vals):\n",
        "            result_image = get_result_from_vecs(all_vecs[i-1], all_vecs[i], alpha)[0]\n",
        "            output_im = tensor2im(result_image)\n",
        "            images.append(np.array(output_im))\n",
        "\n",
        "    animation_path = os.path.join(save_path, f\"{image_name}_animation\")\n",
        "    generate_mp4(animation_path, images, kwargs)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Working on image: 866.jpg\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 25/25 [00:02<00:00,  8.84it/s]\n",
            "100%|██████████| 25/25 [00:02<00:00,  8.69it/s]\n",
            "100%|██████████| 25/25 [00:02<00:00,  8.54it/s]\n",
            "100%|██████████| 25/25 [00:02<00:00,  8.51it/s]\n",
            "100%|██████████| 25/25 [00:03<00:00,  8.08it/s]\n",
            "100%|██████████| 25/25 [00:02<00:00,  8.57it/s]\n",
            "100%|██████████| 25/25 [00:02<00:00,  8.60it/s]\n",
            "100%|██████████| 25/25 [00:02<00:00,  8.67it/s]\n",
            "100%|██████████| 25/25 [00:02<00:00,  8.51it/s]\n",
            "100%|██████████| 25/25 [00:02<00:00,  8.45it/s]\n",
            "100%|██████████| 25/25 [00:02<00:00,  8.61it/s]\n",
            "100%|██████████| 25/25 [00:02<00:00,  8.50it/s]\n",
            "100%|██████████| 25/25 [00:02<00:00,  8.54it/s]\n",
            "100%|██████████| 25/25 [00:02<00:00,  8.50it/s]\n",
            "100%|██████████| 25/25 [00:02<00:00,  8.55it/s]\n",
            "100%|██████████| 25/25 [00:02<00:00,  8.58it/s]\n",
            "100%|██████████| 25/25 [00:02<00:00,  8.55it/s]\n",
            "100%|██████████| 25/25 [00:02<00:00,  8.53it/s]\n",
            "100%|██████████| 25/25 [00:02<00:00,  8.58it/s]\n",
            "100%|██████████| 25/25 [00:02<00:00,  8.74it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Working on image: 1287.jpg\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 25/25 [00:02<00:00,  9.65it/s]\n",
            "100%|██████████| 25/25 [00:02<00:00,  9.57it/s]\n",
            "100%|██████████| 25/25 [00:02<00:00,  9.48it/s]\n",
            "100%|██████████| 25/25 [00:02<00:00,  9.38it/s]\n",
            "100%|██████████| 25/25 [00:02<00:00,  9.38it/s]\n",
            "100%|██████████| 25/25 [00:02<00:00,  9.27it/s]\n",
            "100%|██████████| 25/25 [00:02<00:00,  9.24it/s]\n",
            "100%|██████████| 25/25 [00:02<00:00,  9.19it/s]\n",
            "100%|██████████| 25/25 [00:02<00:00,  9.27it/s]\n",
            "100%|██████████| 25/25 [00:02<00:00,  9.36it/s]\n",
            "100%|██████████| 25/25 [00:02<00:00,  9.28it/s]\n",
            "100%|██████████| 25/25 [00:02<00:00,  9.36it/s]\n",
            "100%|██████████| 25/25 [00:02<00:00,  9.40it/s]\n",
            "100%|██████████| 25/25 [00:02<00:00,  9.30it/s]\n",
            "100%|██████████| 25/25 [00:02<00:00,  9.32it/s]\n",
            "100%|██████████| 25/25 [00:02<00:00,  9.38it/s]\n",
            "100%|██████████| 25/25 [00:02<00:00,  9.34it/s]\n",
            "100%|██████████| 25/25 [00:02<00:00,  9.25it/s]\n",
            "100%|██████████| 25/25 [00:02<00:00,  9.42it/s]\n",
            "100%|██████████| 25/25 [00:02<00:00,  9.23it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Working on image: 2468.jpg\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 25/25 [00:02<00:00,  8.79it/s]\n",
            "100%|██████████| 25/25 [00:02<00:00,  8.40it/s]\n",
            "100%|██████████| 25/25 [00:02<00:00,  8.40it/s]\n",
            "100%|██████████| 25/25 [00:02<00:00,  8.47it/s]\n",
            "100%|██████████| 25/25 [00:02<00:00,  8.43it/s]\n",
            "100%|██████████| 25/25 [00:03<00:00,  8.31it/s]\n",
            "100%|██████████| 25/25 [00:02<00:00,  8.45it/s]\n",
            "100%|██████████| 25/25 [00:02<00:00,  8.41it/s]\n",
            "100%|██████████| 25/25 [00:02<00:00,  8.86it/s]\n",
            "100%|██████████| 25/25 [00:02<00:00,  9.28it/s]\n",
            "100%|██████████| 25/25 [00:02<00:00,  9.31it/s]\n",
            "100%|██████████| 25/25 [00:02<00:00,  8.89it/s]\n",
            "100%|██████████| 25/25 [00:02<00:00,  8.41it/s]\n",
            "100%|██████████| 25/25 [00:03<00:00,  8.27it/s]\n",
            "100%|██████████| 25/25 [00:02<00:00,  8.45it/s]\n",
            "100%|██████████| 25/25 [00:02<00:00,  8.42it/s]\n",
            "100%|██████████| 25/25 [00:02<00:00,  8.35it/s]\n",
            "100%|██████████| 25/25 [00:02<00:00,  8.36it/s]\n",
            "100%|██████████| 25/25 [00:02<00:00,  8.47it/s]\n",
            "100%|██████████| 25/25 [00:02<00:00,  8.70it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}